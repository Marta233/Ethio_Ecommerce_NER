{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T14:47:45.808396Z",
     "iopub.status.busy": "2024-09-29T14:47:45.807958Z",
     "iopub.status.idle": "2024-09-29T14:47:45.831548Z",
     "shell.execute_reply": "2024-09-29T14:47:45.830370Z",
     "shell.execute_reply.started": "2024-09-29T14:47:45.808355Z"
    },
    "id": "TUo0s-HgYtw1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ግራንድI-LOC\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_conll_format(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = []\n",
    "        sentence = []\n",
    "        labels = []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:  # Only append if the sentence list is not empty\n",
    "                    data.append((sentence, labels))\n",
    "                    sentence = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:  # Ensure there are exactly two parts\n",
    "                    token, label = parts\n",
    "                    sentence.append(token)\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Skipping line: {line}\")  # Optional: print to debug which lines are problematic\n",
    "\n",
    "        if sentence:  # Append the last sentence if the file doesn't end with a newline\n",
    "            data.append((sentence, labels))\n",
    "\n",
    "    return pd.DataFrame(data, columns=['tokens', 'labels'])\n",
    "\n",
    "df = load_conll_format(\"/kaggle/input/datset11/dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T14:48:01.893995Z",
     "iopub.status.busy": "2024-09-29T14:48:01.893505Z",
     "iopub.status.idle": "2024-09-29T14:48:01.929231Z",
     "shell.execute_reply": "2024-09-29T14:48:01.928260Z",
     "shell.execute_reply.started": "2024-09-29T14:48:01.893950Z"
    },
    "id": "OvJ5qb7pYxN6",
    "outputId": "3019854e-c3c3-473c-9d4b-00e6bf99bfb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, ሊትር, ፔርሙስ, ለቤት, ለቢሮ, ለሆቴል, አገልግሎት, መዋል, የሚ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ቢላ, የስጋ, የአጥንት, 1000, ብር, ለማዘዝ, ውስን, ፍሬ, ነው, ...</td>\n",
       "      <td>[B-PRODUCT, O, O, B-PRICE, I-PRICE, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ዋስትና, ቅናሽ, አድራሻ, ቁጥር, 1, መገናኛ, ዘፍመሽ, ግራንድ, ሞል...</td>\n",
       "      <td>[O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, ️, አንድ, ብሩሽ, እና, አንድ, ስፓቹላ, ዋጋ, 300, ብር, ለ...</td>\n",
       "      <td>[O, O, O, B-PRODUCT, O, O, B-PRODUCT, B-PRICE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, ️, አንድ, ብሩሽ, እና, አንድ, ስፓቹላ, ዋጋ, 300, ብር, ው...</td>\n",
       "      <td>[O, O, O, B-PRODUCT, O, O, B-PRODUCT, B-PRICE,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[ዋጋ, 1000, ብር, ለማዘዝ, ውስን, ፍሬ, ነው, የቀረው, ️ጥራት, ...</td>\n",
       "      <td>[B-PRICE, I-PRICE, I-PRICE, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[ለቤቶ, ለስጦታ, በጥራት, በቅናሽ, ውስን, ፍሬ, የቀሩ, ዕቃወች, አሁ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[ለልጆ, ለስጦታ, በጥራት, በቅናሽ, ውስን, ፍሬ, የቀሩ, ዕቃወች, አሁ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[4, 1, 400, 10000, ብር, ከ, ነፃ, ማድረስ, ጋር, ለማዘዝ, ...</td>\n",
       "      <td>[O, O, O, B-PRICE, I-PRICE, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[4, 1, 400, 10000, ብር, ከ, ነፃ, ማድረስ, ጋር, ለማዘዝ, ...</td>\n",
       "      <td>[O, O, O, B-PRICE, I-PRICE, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tokens  \\\n",
       "0   [2, ሊትር, ፔርሙስ, ለቤት, ለቢሮ, ለሆቴል, አገልግሎት, መዋል, የሚ...   \n",
       "1   [ቢላ, የስጋ, የአጥንት, 1000, ብር, ለማዘዝ, ውስን, ፍሬ, ነው, ...   \n",
       "2   [ዋስትና, ቅናሽ, አድራሻ, ቁጥር, 1, መገናኛ, ዘፍመሽ, ግራንድ, ሞል...   \n",
       "3   [2, ️, አንድ, ብሩሽ, እና, አንድ, ስፓቹላ, ዋጋ, 300, ብር, ለ...   \n",
       "4   [2, ️, አንድ, ብሩሽ, እና, አንድ, ስፓቹላ, ዋጋ, 300, ብር, ው...   \n",
       "..                                                ...   \n",
       "56  [ዋጋ, 1000, ብር, ለማዘዝ, ውስን, ፍሬ, ነው, የቀረው, ️ጥራት, ...   \n",
       "57  [ለቤቶ, ለስጦታ, በጥራት, በቅናሽ, ውስን, ፍሬ, የቀሩ, ዕቃወች, አሁ...   \n",
       "58  [ለልጆ, ለስጦታ, በጥራት, በቅናሽ, ውስን, ፍሬ, የቀሩ, ዕቃወች, አሁ...   \n",
       "59  [4, 1, 400, 10000, ብር, ከ, ነፃ, ማድረስ, ጋር, ለማዘዝ, ...   \n",
       "60  [4, 1, 400, 10000, ብር, ከ, ነፃ, ማድረስ, ጋር, ለማዘዝ, ...   \n",
       "\n",
       "                                               labels  \n",
       "0   [O, O, O, O, O, O, O, O, O, O, B-PRODUCT, O, O...  \n",
       "1   [B-PRODUCT, O, O, B-PRICE, I-PRICE, O, O, O, O...  \n",
       "2   [O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC, I-...  \n",
       "3   [O, O, O, B-PRODUCT, O, O, B-PRODUCT, B-PRICE,...  \n",
       "4   [O, O, O, B-PRODUCT, O, O, B-PRODUCT, B-PRICE,...  \n",
       "..                                                ...  \n",
       "56  [B-PRICE, I-PRICE, I-PRICE, O, O, O, O, O, O, ...  \n",
       "57  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "58  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "59  [O, O, O, B-PRICE, I-PRICE, O, O, O, O, O, O, ...  \n",
       "60  [O, O, O, B-PRICE, I-PRICE, O, O, O, O, O, O, ...  \n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T15:14:28.112375Z",
     "iopub.status.busy": "2024-09-29T15:14:28.111883Z",
     "iopub.status.idle": "2024-09-29T15:14:28.765247Z",
     "shell.execute_reply": "2024-09-29T15:14:28.763987Z",
     "shell.execute_reply.started": "2024-09-29T15:14:28.112330Z"
    },
    "id": "hsl4T35HNop3",
    "outputId": "6188c1d9-9b2f-4982-d323-445cdb5084ef"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'bert-base-multilingual-cased'  # or \"distilbert-base-multilingual-cased\", \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "def tokenize_and_align_labels(dataframe):\n",
    "    # Tokenize the inputs\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(dataframe['tokens']),\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(dataframe['labels']):\n",
    "        # Get word IDs for the current batch\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        # Initialize label_ids with -100 for padding\n",
    "        label_ids = [-100] * len(tokenized_inputs['input_ids'][i])\n",
    "\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] is not None:\n",
    "                # Get the label for the current token\n",
    "                current_label = label[word_ids[word_index]]\n",
    "                if current_label in label_to_id:\n",
    "                    label_ids[word_index] = label_to_id[current_label]  # Assign the corresponding label id\n",
    "                else:\n",
    "                    print(f\"Warning: Label '{current_label}' not found in label_to_id. Using -100.\")\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Define label mappings\n",
    "label_to_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-PRICE\": 1,\n",
    "    \"I-PRICE\": 2,\n",
    "    \"B-LOC\": 3,\n",
    "    \"I-LOC\": 4,\n",
    "    \"B-PRODUCT\": 5,\n",
    "    \"I-PRODUCT\": 6,\n",
    "    # Add other labels as needed\n",
    "}\n",
    "\n",
    "# Tokenize the data\n",
    "tokenized_data = tokenize_and_align_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:17:01.685812Z",
     "iopub.status.busy": "2024-09-29T15:17:01.685304Z",
     "iopub.status.idle": "2024-09-29T15:17:02.111511Z",
     "shell.execute_reply": "2024-09-29T15:17:02.110175Z",
     "shell.execute_reply.started": "2024-09-29T15:17:01.685764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model: bert-base-multilingual-cased\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_to_id))\n",
    "    print(f\"Successfully loaded model: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T15:17:07.288061Z",
     "iopub.status.busy": "2024-09-29T15:17:07.287186Z",
     "iopub.status.idle": "2024-09-29T15:17:07.722119Z",
     "shell.execute_reply": "2024-09-29T15:17:07.720985Z",
     "shell.execute_reply.started": "2024-09-29T15:17:07.288014Z"
    },
    "id": "pGlwqFLENs4n",
    "outputId": "6f2a2427-fa97-43a5-a99f-a9d6b7e6209a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_to_id))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    logging_steps=10,  # Log after every 10 steps\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",  # Directory to save logs\n",
    "    logging_first_step=True,  # Log the first step as well\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T15:17:12.149764Z",
     "iopub.status.busy": "2024-09-29T15:17:12.149256Z",
     "iopub.status.idle": "2024-09-29T15:19:07.628469Z",
     "shell.execute_reply": "2024-09-29T15:19:07.627303Z",
     "shell.execute_reply.started": "2024-09-29T15:17:12.149687Z"
    },
    "id": "kNfJ1thxOEU4",
    "outputId": "7cfc57a0-430d-40d4-ceb4-85f7eece7cf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ግራንድI-LOC\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Skipping line: ️\n",
      "Number of samples in the dataset: 61\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.973800</td>\n",
       "      <td>0.640335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.973800</td>\n",
       "      <td>0.575930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.973800</td>\n",
       "      <td>0.565332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=0.8299133910073174, metrics={'train_runtime': 114.8245, 'train_samples_per_second': 1.254, 'train_steps_per_second': 0.078, 'total_flos': 9333615433824.0, 'train_loss': 0.8299133910073174, 'epoch': 3.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_conll_format('/kaggle/input/datset11/dataset.txt')\n",
    "tokenized_data = tokenize_and_align_labels(df)\n",
    "from datasets import Dataset\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': tokenized_data['input_ids'],\n",
    "    'attention_mask': tokenized_data['attention_mask'],\n",
    "    'labels': tokenized_data['labels']\n",
    "})\n",
    "\n",
    "print(f\"Number of samples in the dataset: {len(dataset)}\")\n",
    "\n",
    "if len(dataset) > 1:\n",
    "    # Split the dataset for training and validation\n",
    "    train_dataset, val_dataset = dataset.train_test_split(test_size=0.2).values()\n",
    "else:\n",
    "    # Use the entire dataset for training\n",
    "    train_dataset = dataset\n",
    "    val_dataset = dataset  # Or create a separate validation dataset if needed\n",
    "\n",
    "# Set up Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T15:03:44.384170Z",
     "iopub.status.busy": "2024-09-29T15:03:44.383650Z",
     "iopub.status.idle": "2024-09-29T15:03:52.155114Z",
     "shell.execute_reply": "2024-09-29T15:03:52.153931Z",
     "shell.execute_reply.started": "2024-09-29T15:03:44.384124Z"
    },
    "id": "ymZ4RxpyOLDq",
    "outputId": "7f1cf1ef-9f20-466a-da1f-4ea83b035894"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.445087194442749, 'eval_runtime': 7.7518, 'eval_samples_per_second': 1.677, 'eval_steps_per_second': 0.129, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "execution": {
     "iopub.execute_input": "2024-09-29T15:19:58.015776Z",
     "iopub.status.busy": "2024-09-29T15:19:58.015308Z",
     "iopub.status.idle": "2024-09-29T15:20:02.805820Z",
     "shell.execute_reply": "2024-09-29T15:20:02.804523Z",
     "shell.execute_reply.started": "2024-09-29T15:19:58.015732Z"
    },
    "id": "KHOtWLpFOcqS",
    "outputId": "83ae77da-801a-4bf6-88ee-9fbe9dc72021"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Model names for fine-tuning\n",
    "model_names = {\n",
    "    \"xlm-roberta\": \"xlm-roberta-base\",\n",
    "    \"distilbert\": \"distilbert-base-multilingual-cased\",\n",
    "    \"mbert\": \"bert-base-multilingual-cased\"\n",
    "}\n",
    "\n",
    "tokenizers = {}\n",
    "models = {}\n",
    "\n",
    "# Load tokenizers and models\n",
    "for model_key, model_name in model_names.items():\n",
    "    tokenizers[model_key] = AutoTokenizer.from_pretrained(model_name)\n",
    "    models[model_key] = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_to_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:24:44.705365Z",
     "iopub.status.busy": "2024-09-29T15:24:44.704038Z",
     "iopub.status.idle": "2024-09-29T15:24:44.826861Z",
     "shell.execute_reply": "2024-09-29T15:24:44.825484Z",
     "shell.execute_reply.started": "2024-09-29T15:24:44.705277Z"
    },
    "id": "yfvLXCVsQ9TC"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Define function to tokenize and align labels\n",
    "def tokenize_and_align_labels(dataframe, tokenizer):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(dataframe['tokens']),\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(dataframe['labels']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = [-100] * len(tokenized_inputs['input_ids'][i])  # Use -100 for padding tokens\n",
    "        \n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] is not None:  # Check if it's a valid word token\n",
    "                current_label = label[word_ids[word_index]]\n",
    "                label_ids[word_index] = label_to_id[current_label]\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "# Define label mappings\n",
    "label_to_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-PRICE\": 1,\n",
    "    \"I-PRICE\": 2,\n",
    "    \"B-LOC\": 3,\n",
    "    \"I-LOC\": 4,\n",
    "    \"B-PRODUCT\": 5,\n",
    "    \"I-PRODUCT\": 6,\n",
    "    # Add other labels as needed\n",
    "}\n",
    "# Tokenize data for each model\n",
    "tokenized_data = {}\n",
    "for model_key, tokenizer in tokenizers.items():\n",
    "    tokenized_data[model_key] = tokenize_and_align_labels(df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:25:00.310344Z",
     "iopub.status.busy": "2024-09-29T15:25:00.309820Z",
     "iopub.status.idle": "2024-09-29T15:25:00.403230Z",
     "shell.execute_reply": "2024-09-29T15:25:00.402243Z",
     "shell.execute_reply.started": "2024-09-29T15:25:00.310297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the tokenized data into Hugging Face Datasets for training and validation\n",
    "datasets = {}\n",
    "for model_key, data in tokenized_data.items():\n",
    "    dataset = Dataset.from_dict({\n",
    "        'input_ids': data['input_ids'],\n",
    "        'attention_mask': data['attention_mask'],\n",
    "        'labels': data['labels']\n",
    "    })\n",
    "\n",
    "    # Split the dataset into training and validation sets (80/20 split)\n",
    "    datasets[model_key] = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:25:17.589791Z",
     "iopub.status.busy": "2024-09-29T15:25:17.589328Z",
     "iopub.status.idle": "2024-09-29T15:32:22.300995Z",
     "shell.execute_reply": "2024-09-29T15:32:22.299780Z",
     "shell.execute_reply.started": "2024-09-29T15:25:17.589747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: xlm-roberta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 03:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.844292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.591909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.445087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: distilbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.009381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.723416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.665008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: mbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.755505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.665313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.637359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Fine-tune each model and store the trainers\n",
    "trainers = {}\n",
    "for model_key, model in models.items():\n",
    "    trainers[model_key] = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets[model_key]['train'],\n",
    "        eval_dataset=datasets[model_key]['test']\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training model: {model_key}\")\n",
    "    trainers[model_key].train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:32:44.689843Z",
     "iopub.status.busy": "2024-09-29T15:32:44.689333Z",
     "iopub.status.idle": "2024-09-29T15:32:58.696546Z",
     "shell.execute_reply": "2024-09-29T15:32:58.695152Z",
     "shell.execute_reply.started": "2024-09-29T15:32:44.689792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: xlm-roberta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: distilbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: mbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for xlm-roberta: {'eval_loss': 1.445087194442749, 'eval_runtime': 8.1892, 'eval_samples_per_second': 1.587, 'eval_steps_per_second': 0.122, 'epoch': 3.0}\n",
      "Results for distilbert: {'eval_loss': 0.6650081872940063, 'eval_runtime': 2.6282, 'eval_samples_per_second': 4.946, 'eval_steps_per_second': 0.38, 'epoch': 3.0}\n",
      "Results for mbert: {'eval_loss': 0.6373586058616638, 'eval_runtime': 3.0899, 'eval_samples_per_second': 4.207, 'eval_steps_per_second': 0.324, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models on the validation dataset\n",
    "results = {}\n",
    "for model_key, trainer in trainers.items():\n",
    "    print(f\"Evaluating model: {model_key}\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    results[model_key] = eval_result\n",
    "\n",
    "# Print the results\n",
    "for model_key, result in results.items():\n",
    "    print(f\"Results for {model_key}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:35:01.847057Z",
     "iopub.status.busy": "2024-09-29T15:35:01.845795Z",
     "iopub.status.idle": "2024-09-29T15:35:11.856413Z",
     "shell.execute_reply": "2024-09-29T15:35:11.855093Z",
     "shell.execute_reply.started": "2024-09-29T15:35:01.846997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: xlm-roberta\n",
      "Evaluating model: distilbert\n",
      "Evaluating model: mbert\n",
      "Results for xlm-roberta: {'eval_loss': 1.445087194442749, 'eval_runtime': 6.1911, 'eval_samples_per_second': 2.1, 'eval_steps_per_second': 0.162, 'epoch': 3.0}\n",
      "Results for distilbert: {'eval_loss': 0.6650081872940063, 'eval_runtime': 1.2881, 'eval_samples_per_second': 10.092, 'eval_steps_per_second': 0.776, 'epoch': 3.0}\n",
      "Results for mbert: {'eval_loss': 0.6373586058616638, 'eval_runtime': 2.5019, 'eval_samples_per_second': 5.196, 'eval_steps_per_second': 0.4, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models on the validation dataset\n",
    "results = {}\n",
    "for model_key, trainer in trainers.items():\n",
    "    print(f\"Evaluating model: {model_key}\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    results[model_key] = eval_result\n",
    "\n",
    "# Print the evaluation results for each model\n",
    "for model_key, result in results.items():\n",
    "    print(f\"Results for {model_key}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:40:45.720620Z",
     "iopub.status.busy": "2024-09-29T15:40:45.719948Z",
     "iopub.status.idle": "2024-09-29T15:40:45.736793Z",
     "shell.execute_reply": "2024-09-29T15:40:45.734934Z",
     "shell.execute_reply.started": "2024-09-29T15:40:45.720559Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Flatten and filter out padding tokens (-100)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        true_labels.extend([label for label, pred_label in zip(labels[i], preds[i]) if label != -100])\n",
    "        predicted_labels.extend([pred_label for label, pred_label in zip(labels[i], preds[i]) if label != -100])\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    recall = recall_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    f1 = f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T15:40:48.766039Z",
     "iopub.status.busy": "2024-09-29T15:40:48.765556Z",
     "iopub.status.idle": "2024-09-29T15:40:58.641215Z",
     "shell.execute_reply": "2024-09-29T15:40:58.640191Z",
     "shell.execute_reply.started": "2024-09-29T15:40:48.765991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: xlm-roberta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: distilbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: mbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for xlm-roberta: {'eval_loss': 1.445087194442749, 'eval_model_preparation_time': 0.0075, 'eval_accuracy': 0.7983134223471539, 'eval_precision': 0.11460855528652139, 'eval_recall': 0.1419822522184727, 'eval_f1': 0.12683525930888181, 'eval_runtime': 5.2607, 'eval_samples_per_second': 2.471, 'eval_steps_per_second': 0.19}\n",
      "Results for distilbert: {'eval_loss': 0.6650081872940063, 'eval_model_preparation_time': 0.003, 'eval_accuracy': 0.8673036093418259, 'eval_precision': 0.12390051562026085, 'eval_recall': 0.14285714285714285, 'eval_f1': 0.13270527085194508, 'eval_runtime': 1.772, 'eval_samples_per_second': 7.336, 'eval_steps_per_second': 0.564}\n",
      "Results for mbert: {'eval_loss': 0.6373586058616638, 'eval_model_preparation_time': 0.0061, 'eval_accuracy': 0.8425806451612903, 'eval_precision': 0.12036866359447004, 'eval_recall': 0.14285714285714285, 'eval_f1': 0.13065226090436174, 'eval_runtime': 2.7103, 'eval_samples_per_second': 4.796, 'eval_steps_per_second': 0.369}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainers = {}\n",
    "for model_key, model in models.items():\n",
    "    trainers[model_key] = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets[model_key]['train'],\n",
    "        eval_dataset=datasets[model_key]['test'],\n",
    "        compute_metrics=compute_metrics  # Use the updated compute_metrics function\n",
    "    )\n",
    "\n",
    "# Evaluate the models\n",
    "results = {}\n",
    "for model_key, trainer in trainers.items():\n",
    "    print(f\"Evaluating model: {model_key}\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    results[model_key] = eval_result\n",
    "\n",
    "# Print results\n",
    "for model_key, result in results.items():\n",
    "    print(f\"Results for {model_key}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5788325,
     "sourceId": 9509572,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
